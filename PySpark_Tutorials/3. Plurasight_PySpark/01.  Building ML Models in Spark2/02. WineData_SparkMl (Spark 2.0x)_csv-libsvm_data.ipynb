{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the SQLContext\n",
    "The entry point into all functionality in Spark SQL <br />\n",
    "The SQLContext can be used to create a Spark Dataframe (as opposed to an RDD) from a data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataset location: </b>https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data <br />\n",
    "The same dataset we have used so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Predicting the grape variety from wine characteristics') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# header is absent\n",
    "rawData = spark.read\\\n",
    "            .format('csv')\\\n",
    "            .option('header', 'false').load('../datasets/wine.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the schema of the loaded DataFrame\n",
    "* There are no column names\n",
    "* All values are loaded as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string, _c12: string, _c13: string]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the values in the top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+----+----+---+----+----+---+----+----+----+----+----+\n",
      "|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7|_c8| _c9|_c10|_c11|_c12|_c13|\n",
      "+---+-----+----+----+----+---+----+----+---+----+----+----+----+----+\n",
      "|  1|14.23|1.71|2.43|15.6|127| 2.8|3.06|.28|2.29|5.64|1.04|3.92|1065|\n",
      "|  1| 13.2|1.78|2.14|11.2|100|2.65|2.76|.26|1.28|4.38|1.05| 3.4|1050|\n",
      "|  1|13.16|2.36|2.67|18.6|101| 2.8|3.24| .3|2.81|5.68|1.03|3.17|1185|\n",
      "|  1|14.37|1.95| 2.5|16.8|113|3.85|3.49|.24|2.18| 7.8| .86|3.45|1480|\n",
      "|  1|13.24|2.59|2.87|  21|118| 2.8|2.69|.39|1.82|4.32|1.04|2.93| 735|\n",
      "+---+-----+----+----+----+---+----+----+---+----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign names to each of the columns\n",
    "And create a new dataframe from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+----+-------------+---------+------------+----------+-------------------+---------------+--------------+----+----+-------+\n",
      "|Label|Alcohol|MalicAcid| Ash|AshAlkalinity|Magnesium|TotalPhenols|Flavanoids|NonflavanoidPhenols|Proanthocyanins|ColorIntensity| Hue|  OD|Proline|\n",
      "+-----+-------+---------+----+-------------+---------+------------+----------+-------------------+---------------+--------------+----+----+-------+\n",
      "|    1|  14.23|     1.71|2.43|         15.6|      127|         2.8|      3.06|                .28|           2.29|          5.64|1.04|3.92|   1065|\n",
      "|    1|   13.2|     1.78|2.14|         11.2|      100|        2.65|      2.76|                .26|           1.28|          4.38|1.05| 3.4|   1050|\n",
      "+-----+-------+---------+----+-------------+---------+------------+----------+-------------------+---------------+--------------+----+----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = rawData.toDF('Label',\n",
    "                'Alcohol',\n",
    "                'MalicAcid',\n",
    "                'Ash',\n",
    "                'AshAlkalinity',\n",
    "                'Magnesium',\n",
    "                'TotalPhenols',\n",
    "                'Flavanoids',\n",
    "                'NonflavanoidPhenols',\n",
    "                'Proanthocyanins',\n",
    "                'ColorIntensity',\n",
    "                'Hue',\n",
    "                'OD',\n",
    "                'Proline'\n",
    "                )\n",
    "\n",
    "dataset.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm that the dataset contains the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Label',\n",
       " 'Alcohol',\n",
       " 'MalicAcid',\n",
       " 'Ash',\n",
       " 'AshAlkalinity',\n",
       " 'Magnesium',\n",
       " 'TotalPhenols',\n",
       " 'Flavanoids',\n",
       " 'NonflavanoidPhenols',\n",
       " 'Proanthocyanins',\n",
       " 'ColorIntensity',\n",
       " 'Hue',\n",
       " 'OD',\n",
       " 'Proline']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the dataset with the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a vectorize function to store the data in the required format for our ML models\n",
    "The ML package needs data be put in a (label: Double, features: Vector) DataFrame format with correspondingly named fields. The vectorize() function does just that\n",
    "* We perform a manual transformation of our dataset here\n",
    "* Spark ML also supplies built-in transformers which we will use shortly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# we can also use vector assembler\n",
    "def vectorize(data):\n",
    "    return data.rdd.map(lambda r: [r[0], Vectors.dense(r[1:])])\\\n",
    "                                        .toDF(['label','features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function will leave the r[0] separate and combine rest feature values into a vector. Then that rdd will be converted into a dataframe with 2 columns i.e. 1 label column, and other dense vector column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert our data set into the vectorized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedData = vectorize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[14.23,1.71,2.43,...|\n",
      "|    1|[13.2,1.78,2.14,1...|\n",
      "|    1|[13.16,2.36,2.67,...|\n",
      "|    1|[14.37,1.95,2.5,1...|\n",
      "|    1|[13.24,2.59,2.87,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizedData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the transformed dataset\n",
    "The features are now a DenseVector with an array of feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='1', features=DenseVector([14.23, 1.71, 2.43, 15.6, 127.0, 2.8, 3.06, 0.28, 2.29, 5.64, 1.04, 3.92, 1065.0])),\n",
       " Row(label='1', features=DenseVector([13.2, 1.78, 2.14, 11.2, 100.0, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.4, 1050.0])),\n",
       " Row(label='1', features=DenseVector([13.16, 2.36, 2.67, 18.6, 101.0, 2.8, 3.24, 0.3, 2.81, 5.68, 1.03, 3.17, 1185.0])),\n",
       " Row(label='1', features=DenseVector([14.37, 1.95, 2.5, 16.8, 113.0, 3.85, 3.49, 0.24, 2.18, 7.8, 0.86, 3.45, 1480.0])),\n",
       " Row(label='1', features=DenseVector([13.24, 2.59, 2.87, 21.0, 118.0, 2.8, 2.69, 0.39, 1.82, 4.32, 1.04, 2.93, 735.0]))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizedData.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StringIndexer \n",
    "* It's a feature transformer (can also be used for labels)\n",
    "* Encodes a string column to a column of indices. The indices are in [0, numLabels), ordered by value frequencies, so the most frequent value gets index 0\n",
    "* The label needs to be of type Double which will be handled by StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels although look numeric it is actuallY is a string\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol='label',\n",
    "                             outputCol='indexedLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the label in the vectorized dataset with the StringIndexer\n",
    "We get a new label field called indexedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='1', features=DenseVector([14.23, 1.71, 2.43, 15.6, 127.0, 2.8, 3.06, 0.28, 2.29, 5.64, 1.04, 3.92, 1065.0]), indexedLabel=1.0),\n",
       " Row(label='1', features=DenseVector([13.2, 1.78, 2.14, 11.2, 100.0, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.4, 1050.0]), indexedLabel=1.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexedData = labelIndexer.fit(vectorizedData).transform(vectorizedData)\n",
    "indexedData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm that the indexedLabel is in Double format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: string, features: vector, indexedLabel: double]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|    3|\n",
      "|    1|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexedData.select('label').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|indexedLabel|\n",
      "+------------+\n",
      "|         0.0|\n",
      "|         1.0|\n",
      "|         2.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexedData.select('indexedLabel').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the vectorized data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = indexedData.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree Classifier\n",
    "* Specify the features and label columns\n",
    "* <b>maxDepth: </b>The maximum depth of the decision tree\n",
    "* <b>impurity: </b>We use gini instead of entropy. Gini measurement is the probability of a random sample being classified correctly. Entropy is a measure of information (seek to maximize information gain when making a split). Outputs generally don't vary much when either option is chosen, but entropy may take longer to compute as it calculates a logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(\n",
    "    labelCol='indexedLabel', \n",
    "    featuresCol='features',\n",
    "    maxDepth=3,\n",
    "    impurity='gini'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traing the model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dtree.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Spark ML's MulticlassClassificationEvaluator to evaluate the model\n",
    "* Used to evaluate classification models\n",
    "* It takes a set of labels and predictions as input\n",
    "* Similar to (but not the same as MulticlassMetrics in MLLib)\n",
    "* <b>metricName: </b>Can be **precision, recall, weightedPrecision, weightedRecall and f1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',\n",
    "                                              predictionCol='prediction', \n",
    "                                              metricName='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the test data using our model to include predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+--------------+--------------------+----------+\n",
      "|label|            features|indexedLabel| rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+------------+--------------+--------------------+----------+\n",
      "|    1|[13.05,1.65,2.55,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.05,1.73,2.04,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.05,1.77,2.1,1...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.05,2.05,3.22,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.24,3.98,2.29,...|         1.0|[50.0,1.0,0.0]|[0.98039215686274...|       0.0|\n",
      "|    1|[13.3,1.72,2.14,1...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.51,1.8,2.65,1...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.56,1.71,2.31,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.56,1.73,2.46,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.58,1.66,2.36,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.63,1.81,2.7,1...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.64,3.1,2.56,1...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.75,1.73,2.41,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.83,1.57,2.62,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.83,1.65,2.6,1...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.88,1.89,2.59,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[13.94,1.73,2.27,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[14.19,1.59,2.48,...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[14.22,1.7,2.3,16...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|    1|[14.3,1.92,2.72,2...|         1.0|[0.0,38.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "+-----+--------------------+------------+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There are 3 unique labels/targets\n",
    "transformed_data = model.transform(testData)\n",
    "transformed_data.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure accuracy of model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 value: 0.8621951219512195\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.getMetricName(), \n",
    "      'value:', \n",
    "      evaluator.evaluate(transformed_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View only the columns relevant for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+\n",
      "|indexedLabel|prediction|         probability|\n",
      "+------------+----------+--------------------+\n",
      "|         1.0|       1.0|       [0.0,1.0,0.0]|\n",
      "|         1.0|       1.0|       [0.0,1.0,0.0]|\n",
      "|         1.0|       1.0|       [0.0,1.0,0.0]|\n",
      "|         1.0|       1.0|       [0.0,1.0,0.0]|\n",
      "|         1.0|       0.0|[0.98039215686274...|\n",
      "+------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = transformed_data.select('indexedLabel', 'prediction', 'probability')\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark dataframes can also be converted to Pandas dataframes\n",
    "View our predictions as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexedLabel</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.9803921568627451, 0.0196078431372549, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    indexedLabel  prediction                                    probability\n",
       "0            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "1            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "2            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "3            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "4            1.0         0.0  [0.9803921568627451, 0.0196078431372549, 0.0]\n",
       "5            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "6            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "7            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "8            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "9            1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "10           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "11           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "12           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "13           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "14           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "15           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "16           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "17           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "18           1.0         1.0                                [0.0, 1.0, 0.0]\n",
       "19           1.0         1.0                                [0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.toPandas().head(20)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
